---
title: 'Capital Bikeshare Dataset Analysis'
author: "Michael Alpas, Mohit Singh and Upendra Yadav"
date: "August 07, 2020"
output:
  html_document: 
    theme: readable
    toc: yes  
  pdf_document: default
urlcolor: cyan
---
---

```{r setup, echo = FALSE, message = FALSE, warning = FALSE}
options(scipen = 1, digits = 4, width = 80)
```

# Introduction

---

## Overview

For this project, we would like to simulate that Team Outlier is a team of Data Scientists that Capital Bikeshare company hired to come up with data driven answers to help them with their decisions.

The following business questions will be guided by the two-year historical log corresponding to years 2011 and 2012.

 * Capital Bikeshare would like to have a targeted marketing strategy. The Team Outlier need to determine the recommended season to have marketing promotional offers to increase the number of customers.
 * The company also need to reduce operational expenses by looking at the manpower needed for Holidays and Regular days. Team Outlier will predict the number of people needed during Holidays vs Regular day.
 
Bike-sharing rental process is highly correlated to the environmental and seasonal settings. For instance, weather conditions, precipitation, day of week, season, hour of the day, etc. can affect the rental behaviors. The core data set is related to the two-year historical log corresponding to years 2011 and 2012 from [Capital Bikeshare](http://capitalbikeshare.com/system-data) system, Washington D.C., USA which is publicly available. Our source ([UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/bike+sharing+dataset)) aggregated the data on two hourly and daily basis. They extracted and added the corresponding weather and seasonal information. Weather information were extracted from http://www.freemeteo.com. 

There are two datasets -- `hour.csv` and `day.csv`. Both datasets have the same fields except `hr` which is not available in `day.csv`. The `hour.csv` contains bike sharing counts aggregated on hourly basis and it has records of 17379 hours. The `day.csv` contains bike sharing counts aggregated on daily basis and it has records of 731 days.

---

# Methods

---

## Targeted Marketing Strategy Analysis
### Loading the Dataset

```{r}
library(readr)
day_data = read.csv("dataset/day.csv")
# knitr::kable(head(day_data)[, 1:15])
head(day_data)

hour_data = read.csv("dataset/hour.csv")
# knitr::kable(head(hour_data)[, 1:15])
head(hour_data)
```

### Filter the data based on season
```{r}
# spring filtered data
spring_data = subset(day_data, day_data$season == 1)

# summer filtered data
summer_data = subset(day_data, day_data$season == 2)

# fall filtered data
fall_data   = subset(day_data, day_data$season == 3)

# winter filtered data
winter_data = subset(day_data, day_data$season == 4)
```

### Remove Possible NA

```{r}
# remove NA
spring_data = na.omit(spring_data)
summer_data = na.omit(summer_data)
fall_data = na.omit(fall_data)
winter_data = na.omit(winter_data)
```

### Quick Comparison

let's take a quick look with the filtered data.

```{r season_plot, fig.height = 8, fig.width = 10, message=FALSE, warning=FALSE}
# plot to see the difference 
par(mfrow=c(2,2))
hist(spring_data$cnt, col = "dodgerblue",border = "darkorange", xlab = "count", main = "Spring Daily Rental Bike Summary")
hist(summer_data$cnt, col = "dodgerblue",border = "darkorange", xlab = "count", main = "Summer Daily Rental Bike Summary")
hist(summer_data$cnt, col = "dodgerblue",border = "darkorange", xlab = "count", main = "Fall Daily Rental Bike Summary")
hist(winter_data$cnt, col = "dodgerblue",border = "darkorange", xlab = "count", main = "Winter Daily Rental Bike Summary")

```

### Collinearity Check

We will remove the `instant` and `dteday` variables since these are data reference index and so we can use the `cor()` and `pair()` functions to see what are the predictors that are highly correlated.

```{r}
day_data_converted = day_data[3:16]

# convert all factor variables to numeric in order to call cor()
for(name in colnames(day_data_converted)) {
  if (is.integer(day_data_converted[[name]]))
    day_data_converted[[name]] = as.numeric(day_data_converted[[name]])
}
```

Let's visually check the correlation between the predictors. We would see immediately that there are 2 interesting sets of variables. 1) `temp` and `atemp` 2) `registered` and `cnt`. 

```{r cor_plot, fig.height = 10, fig.width = 10, message=FALSE, warning=FALSE}
library(faraway)
pairs(day_data_converted, col = "dodgerblue")
```

Now, lets check using `cor()` function. We will use cor values > 0.5 to see the predictors that are correlated

```{r}
all_cor = round(cor(day_data_converted), 2)
(correlated_predictors = sort(abs(all_cor["cnt", abs(all_cor["cnt", ]) > 0.5]), decreasing = TRUE)[-1])
```

Based on the results of `cor()` computation, the above predictors will be helpful to predict the recommended `season` to run promotional offers to reach company's goal of increasing the number of customers.

### Predictor Selection

We will explore for the best model we can use. First, we build a model based on the significant predictors that have high correlation and also build a full model for comparison. Comparing the Adjusted $R^2$, both of them have high equal values which means the correlation are reliable.

```{r message=FALSE, warning=FALSE}
library(knitr)
library(kableExtra)

cor_model = lm(cnt ~ registered + casual + temp + atemp + yr, data = day_data_converted)
summary(cor_model)$adj.r.squared

full_day_model = lm(cnt ~ ., data = day_data_converted)
summary(full_day_model)$adj.r.squared

comp_results = data.frame(
  "Correlated Model" = c(
    "Adjusted R-squared" = summary(cor_model)$adj.r.squared,
    "R-Squared"          = summary(cor_model)$r.squared
  ),
  "Full Model" = c(
    "Adjusted R-squared" = summary(full_day_model)$adj.r.squared,
    "R-Squared"          = summary(full_day_model)$r.squared
  )
)

kable(comp_results) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))

```

Both models has good Adjusted $R^2$. However, we want to check if there are predictors that has high **variance inflation factor (VIF)** to quantify the effect of collinearity on the variance of our regression estimates. It is also interesting to compare the VIF of the 2 models.

```{r message=FALSE, warning=FALSE}
sort(vif(cor_model)[vif(cor_model) > 5], decreasing = TRUE)

sort(vif(full_day_model)[vif(full_day_model) > 5], decreasing = TRUE)

```

Based on the above comparison, the `atemp` and `temp` are consistent concern for both models because of huge collinearity issue. 

Running an `F-test`, let see what would be the preferred model. We observed through the `F-test` that we prefer the smaller model.

```{r message=FALSE, warning=FALSE}
anova(cor_model, full_day_model)

```

Let's take the `cor_model` and remove the 2 highest VIF's. Then for the remaining variables, instead checking individually, we will do an exhaustive search.  

```{r message=FALSE, warning=FALSE}
cor_model_no_high_vif = lm(cnt ~ registered + casual + yr, data = day_data_converted)

library(leaps)
all_cnt_mod = summary(regsubsets(cnt ~ ., data = day_data_converted, really.big = FALSE))
best_r2_ind = which.max(all_cnt_mod$adjr2)

# extract the predictor of the model
all_cnt_mod$which[best_r2_ind, ]

```

We don't think we need to optimize it for `LOOCV RMSE` since **casual** and **registered** predictors has the highest Adjusted $R^2$.

### Compute Prediction Each Season

For computing the mean prediction, we will use the predictors that we identified from the previous process.

```{r}
best_model = lm(cnt ~ registered + casual, data = day_data)
spring_pred = mean(predict(best_model, newdata = spring_data, interval = c("prediction"), level = 0.99))

summer_pred = mean(predict(best_model, newdata = summer_data, interval = c("prediction"), level = 0.99))

fall_pred = mean(predict(best_model, newdata = fall_data, interval = c("prediction"), level = 0.99))

winter_pred = mean(predict(best_model, newdata = winter_data, interval = c("prediction"), level = 0.99))

# create table for prediction results
pred_results = data.frame(
  "prediction" = c(
    "Spring" = spring_pred,
    "Summer" = summer_pred,
    "Fall"   = fall_pred,
    "Winter" = winter_pred
  )
)

kable(pred_results) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))

```


## Operational Expenses Analysis

---

# Results

## Targeted Marketing Strategy Analysis

Based on the `F-test`, we observed that we prefer the smaller model we got from checking the collinearity which has the predictors -- **registered**, **casual**, **temp**, **atemp** and **yr** .  From the preferred model, we decided to find the best model by removing the highest `VIF` and we ran exhaustive search to check every possible model. We ended up using **registered** and **casual** variables to compute the predictions for each season.

## Operational Expenses Analysis

---

# Discussion

## Targeted Marketing Strategy Analysis

On our preliminary assumption, Winter will be the season that would need an enhanced marketing strategy but it turned out upon finding the best model, Spring is the season that would require a better marketing strategy to attract additional customers. Interrogating the best model `best_model = lm(cnt ~ registered + casual, data = day_data)`, the value of `cnt` is the sum of `registered` and `casual`, which would make that it highly correlated to the response.

If given additional time, we would like to explore why Spring season got the lowest prediction compared to our initial assumption of Winter season. Are there any methods that would lead us to a different best model? Are people biking a lot during Winter because they want the excitement of having snow and cold temperature? It will also interesting to gather data around how often a customer rent a bike, a comparison of registered vs casual bike riders and the type of bicycle -- mountain bike, fat bike or road bike.


## Operational Expenses Analysis

---

# Appendix

---

